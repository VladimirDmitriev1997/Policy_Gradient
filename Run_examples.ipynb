{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run_examples.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzEUUjCJNRMe"
      },
      "source": [
        "import Policy_Gradient_CV as PG\n",
        "from scipy.integrate import quad\n",
        "from scipy import special\n",
        "import sys \n",
        "import os\n",
        "import torch  \n",
        "import gym\n",
        "import numpy as np  \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "m9Gf8JxhNVVk",
        "outputId": "70030876-3e5f-43fb-8f70-74040c2223d5"
      },
      "source": [
        "\n",
        "env = gym.make(\"MountainCarContinuous-v0\")\n",
        "env.seed(1)\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "state_dim = 2\n",
        "action_dim = 1\n",
        "sampler_parameters_dim = 2\n",
        "hidden_size = 128\n",
        "agent = utils.REINFORCE_Agent(state_dim, sampler_parameters_dim, hidden_size)\n",
        "max_episode_num = 100\n",
        "max_steps = 10000\n",
        "gamma = 0.9999\n",
        "\n",
        "\n",
        "\n",
        "numsteps = []\n",
        "avg_numsteps = []\n",
        "all_rewards = []\n",
        "l = []\n",
        "final_flag = 1\n",
        "R = []\n",
        "R_ = []\n",
        "\n",
        "for episode in range(max_episode_num):\n",
        "  process = utils.MDP(env, agent, max_steps, gamma, state_dim, action_dim)\n",
        "  while final_flag == 1:\n",
        "    final_flag = process.step()\n",
        "  final_flag = 1\n",
        "  cum_rew, mean_rew = process.finalize_trajectory()\n",
        "  print(cum_rew, mean_rew)\n",
        "  R.append(cum_rew)\n",
        "  R_.append(mean_rew)\n",
        "        \n",
        "plt.plot(R)\n",
        "plt.plot(R_)\n",
        "plt.xlabel('Episode')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0d8bc167542e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msampler_parameters_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREINFORCE_Agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler_parameters_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmax_episode_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmax_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJWpUS-fZPIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9e166e4-2687-4f6a-d179-e3a365d0436a"
      },
      "source": [
        "\n",
        "\n",
        "env = gym.make(\"MountainCarContinuous-v0\")\n",
        "env.seed(1)\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "state_dim = 2\n",
        "action_dim = 1\n",
        "sampler_parameters_dim = 2\n",
        "hidden_size = 128\n",
        "agent = utils.REINFORCE_Agent(state_dim, sampler_parameters_dim, hidden_size)\n",
        "max_episode_num = 100\n",
        "max_steps = 10000\n",
        "gamma = 0.9999\n",
        "lag = 5\n",
        "K = 2\n",
        "burn_in = 2\n",
        "burn_off = 2\n",
        "polynomial = utils.herm\n",
        "\n",
        "\n",
        "\n",
        "numsteps = []\n",
        "avg_numsteps = []\n",
        "all_rewards = []\n",
        "l = []\n",
        "final_flag = 1\n",
        "R = []\n",
        "R_ = []\n",
        "R_CV = []\n",
        "R_CV_ = []\n",
        "\n",
        "for episode in range(max_episode_num):\n",
        "  if episode%10 == 0:\n",
        "    status ='work'\n",
        "    cv = utils.CV(lag, K, burn_in, burn_off, polynomial, max_steps, state_dim, action_dim, status, lr = 0.001)\n",
        "  else:\n",
        "    status ='learning'\n",
        "    cv = utils.CV(lag, K, burn_in, burn_off, polynomial, max_steps, state_dim, action_dim, status, lr = 0.001)\n",
        "  cv.init_regression(state_dim, action_dim)\n",
        "  process = utils.MDP(env, agent, max_steps, gamma, state_dim, action_dim, cv)\n",
        "  while final_flag == 1:\n",
        "    final_flag = process.step()\n",
        "  final_flag = 1\n",
        "  cum_rew, mean_rew  = process.finalize_trajectory()\n",
        "  print(cum_rew, mean_rew)\n",
        "  R.append(cum_rew)\n",
        "  R_.append(mean_rew)\n",
        "  #R_CV.append(cv)\n",
        "  #R_CV_.append(cv_)\n",
        "plt.plot(R)\n",
        "#plt.plot(R_)\n",
        "#plt.plot(R_CV)\n",
        "#plt.plot(R_CV_)\n",
        "#plt.xlabel('Episode')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/REINFORCE.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Q = torch.tensor(q,dtype = torch.float32, requires_grad=True).cuda()\n",
            "/content/REINFORCE.py:284: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(Q[t-q,:self.action_dim+ self.state_dim].detach().clone(),dtype = torch.float32, requires_grad=True).detach().cpu()\n",
            "/content/REINFORCE.py:285: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x,dtype = torch.float32, requires_grad=True).reshape((1,-1)).cuda()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-3.1712856638609788 -0.003174460123984964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/REINFORCE.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(Q[t-q,:self.action_dim+ self.state_dim].detach().clone(),dtype = torch.float32, requires_grad=True).detach().cpu()\n",
            "/content/REINFORCE.py:250: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x,dtype = torch.float32, requires_grad=True).reshape((1,-1)).cuda()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-3.104209365126068 -0.003107316681807876\n",
            "-3.007965919293503 -0.0030109768961896926\n",
            "-3.0521166783621636 -0.003055171850212376\n",
            "-3.166985575914794 -0.0031701557316464405\n",
            "-2.9738045299033047 -0.0029767813112145194\n",
            "-3.009589494686378 -0.0030126020967831614\n",
            "-3.0287450719599405 -0.0030317768488087493\n",
            "-3.104006220360413 -0.0031071133336941074\n",
            "-3.0785669894154903 -0.003081648638053544\n",
            "-3.073138808292848 -0.003076215023316164\n",
            "-3.0602602457425307 -0.0030633235693118426\n",
            "-3.0079247111715897 -0.003010935646818408\n",
            "-2.974955416826823 -0.0029779333501769997\n",
            "-3.075434993842517 -0.003078513507349867\n",
            "-3.026713206846671 -0.0030297429497964674\n",
            "-3.044189807684159 -0.0030472370447288876\n",
            "-3.0503225663349363 -0.0030533759422772134\n",
            "-2.992299724932634 -0.0029952950199525867\n",
            "-3.021188251424861 -0.0030242124638887495\n",
            "-2.9457673638480766 -0.0029487160799280044\n",
            "-2.994269680695343 -0.002997266947642986\n",
            "-2.972272736201454 -0.0029752479841856395\n",
            "-2.972913557776134 -0.002975889447223357\n",
            "-3.0171133304089555 -0.003020133463872828\n",
            "-2.986577668561032 -0.002989567235796829\n",
            "-2.9747890143778517 -0.002977766781159011\n",
            "-2.930094032522759 -0.0029330270595823416\n",
            "-2.9461692077216837 -0.0029491183260477315\n",
            "-2.92061403388231 -0.0029235375714537636\n",
            "-2.997635255146138 -0.003000635891037175\n",
            "-3.0000336700167276 -0.003003036706723451\n",
            "-2.909515987510152 -0.002912428415926078\n",
            "-3.006865374695903 -0.003009875249945849\n",
            "-3.012886473968508 -0.003015902376344853\n",
            "-2.9846473726115876 -0.0029876350076192067\n",
            "-2.98771969392235 -0.002990710404326677\n",
            "-2.9690708500962035 -0.002972042892989193\n",
            "-2.9503453853723802 -0.0029532986840564365\n",
            "-2.930161040483399 -0.002933094134618017\n",
            "-2.9775651996325347 -0.002980545745377913\n",
            "-2.8961554668057303 -0.0028990545213270573\n",
            "-2.985716723319327 -0.002988705428748075\n",
            "-2.9221679889045764 -0.002925093081986563\n",
            "-2.9578910294667815 -0.0029608518813481295\n",
            "-2.901479450874898 -0.002904383834709608\n",
            "-2.927117094008837 -0.002930047141149987\n",
            "-2.947179768153344 -0.002950129898051395\n",
            "-2.9003554875002093 -0.002903258746246456\n",
            "-2.943406194912466 -0.002946352547459926\n",
            "-2.939274863857252 -0.00294221708093819\n",
            "-2.940211780929271 -0.002943154935865136\n",
            "-2.8867098297319957 -0.0028895994291611568\n",
            "-2.91243550573704 -0.002915350856593634\n",
            "-2.9270761803242094 -0.0029300061865107203\n",
            "-2.95064820406769 -0.0029536018058735638\n",
            "-2.93136246437635 -0.0029342967611374875\n",
            "-2.913888246925716 -0.0029168050519776936\n",
            "-2.925164465585934 -0.002928092558144078\n",
            "-2.929980796279086 -0.002932913709989075\n",
            "-2.8990858430048076 -0.0029019878308356433\n",
            "-2.9288243802253118 -0.0029317561363616735\n",
            "-2.911165618529877 -0.002914079698228105\n",
            "-2.883794352206503 -0.002886681033239743\n",
            "-2.8945184748159924 -0.0028974158907066993\n",
            "-2.899984334767667 -0.0029028872219896565\n",
            "-2.9092459567898836 -0.0029121581149047886\n",
            "-2.904058846777567 -0.0029069658125901576\n",
            "-2.8942604678222015 -0.002897157625447649\n",
            "-2.908245340092938 -0.002911156496589527\n",
            "-2.9204265125922366 -0.0029233498624546914\n",
            "-2.9049051173657636 -0.00290781293029606\n",
            "-2.921183732038074 -0.002924107839877952\n",
            "-2.8845356253319276 -0.002887423048380308\n",
            "-2.9069819621989925 -0.0029098918540530457\n",
            "-2.9159720696996194 -0.0029188909606602796\n",
            "-2.917803244658398 -0.002920723968627025\n",
            "-2.898054549859716 -0.002900955505365081\n",
            "-2.9069034209528386 -0.0029098132341870255\n",
            "-2.9106636249226416 -0.0029135772021247662\n",
            "-2.8876856568908806 -0.0028905762331240046\n",
            "-2.906092680060003 -0.0029090016817417447\n",
            "-2.9176043096030666 -0.002920524834437504\n",
            "-2.8978940661213364 -0.002900794860982319\n",
            "-2.9267108982981958 -0.0029296405388370326\n",
            "-2.904338588119618 -0.0029072458339535717\n",
            "-2.9336894603851134 -0.002936626086471585\n",
            "-2.9086656730722504 -0.002911577250322573\n",
            "-2.8934581294355994 -0.002896354483919519\n",
            "-2.902429747196778 -0.002905335082279057\n",
            "-2.907926090015137 -0.002910836926942079\n",
            "-2.9124410932709406 -0.0029153564497206613\n",
            "-2.9184901971295742 -0.0029214116087383124\n",
            "-2.920117039133291 -0.0029230400792125038\n",
            "-2.9081697280332226 -0.002911080808842065\n",
            "-2.919727424753418 -0.0029226500748282466\n",
            "-2.9096017398863907 -0.0029125142541405313\n",
            "-2.9237482672811255 -0.002926674942223349\n",
            "-2.914560647516926 -0.0029174781256425687\n",
            "-2.9233400137271253 -0.0029262662800071323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pniSRXFbsamF",
        "outputId": "13a2bdc9-18f8-4e3c-82c6-76da0fe23d15"
      },
      "source": [
        "env = gym.make(\"MountainCarContinuous-v0\")\n",
        "env.seed(1)\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "state_dim = 2\n",
        "action_dim = 1\n",
        "sampler_parameters_dim = 2\n",
        "hidden_size = 128\n",
        "agent = PG.A2C_Agent(state_dim, sampler_parameters_dim, hidden_size)\n",
        "max_episode_num = 100\n",
        "max_steps = 10000\n",
        "gamma = 0.9999\n",
        "\n",
        "\n",
        "\n",
        "numsteps = []\n",
        "avg_numsteps = []\n",
        "all_rewards = []\n",
        "l = []\n",
        "final_flag = 1\n",
        "R = []\n",
        "R_ = []\n",
        "\n",
        "for episode in range(max_episode_num):\n",
        "  process = PG.MDP(env, agent, max_steps, gamma, state_dim, action_dim)\n",
        "  while final_flag == 1:\n",
        "    final_flag = process.step()\n",
        "  final_flag = 1\n",
        "  cum_rew, mean_rew = process.finalize_trajectory()\n",
        "  if episode%10 == 0:\n",
        "    print(cum_rew, mean_rew)\n",
        "  R.append(cum_rew)\n",
        "  R_.append(mean_rew)\n",
        "        \n",
        "plt.plot(R)\n",
        "plt.plot(R_)\n",
        "plt.xlabel('Episode')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Policy_Gradient_CV.py:196: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  utils.clip_grad_norm(self.parameters(), 40)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-45.604101555132026 -0.04564975130643847\n",
            "-41.2484878535303 -0.04128977763116146\n",
            "-38.900039370532554 -0.03893897834888144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "674AaXaprmgk"
      },
      "source": [
        "if episode%10 == 0:\n",
        "    status ='work'\n",
        "    cv = utils.CV(lag, K, burn_in, burn_off, polynomial, max_steps, state_dim, action_dim, status, lr = 0.001)\n",
        "  else:\n",
        "    status ='learning'\n",
        "    cv = utils.CV(lag, K, burn_in, burn_off, polynomial, max_steps, state_dim, action_dim, status, lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JucFxKkcLxak",
        "outputId": "268135d8-a428-406a-e0fe-9c8ed0cb9cd9"
      },
      "source": [
        "env = gym.make(\"MountainCarContinuous-v0\")\n",
        "env.seed(1)\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "state_dim = 2\n",
        "action_dim = 1\n",
        "sampler_parameters_dim = 2\n",
        "hidden_size = 128\n",
        "agent = PG.A2C_Agent(state_dim, sampler_parameters_dim, hidden_size)\n",
        "max_episode_num = 100\n",
        "max_steps = 10000\n",
        "gamma = 0.9999\n",
        "lag = 5\n",
        "K = 2\n",
        "burn_in = 2\n",
        "burn_off = 2\n",
        "polynomial = PG.herm\n",
        "\n",
        "\n",
        "numsteps = []\n",
        "avg_numsteps = []\n",
        "all_rewards = []\n",
        "l = []\n",
        "final_flag = 1\n",
        "R = []\n",
        "R_ = []\n",
        "\n",
        "for episode in range(max_episode_num):\n",
        "  if episode%10 == 0:\n",
        "    status ='work'\n",
        "    cv = PG.CV(lag, K, burn_in, burn_off, polynomial, max_steps, state_dim, action_dim, status, lr = 0.001)\n",
        "  else:\n",
        "    status ='learning'\n",
        "    cv = PG.CV(lag, K, burn_in, burn_off, polynomial, max_steps, state_dim, action_dim, status, lr = 0.001)\n",
        "  cv.init_regression(state_dim, action_dim)\n",
        "  process = PG.MDP(env, agent, max_steps, gamma, state_dim, action_dim, cv)\n",
        "  while final_flag == 1:\n",
        "    final_flag = process.step()\n",
        "  final_flag = 1\n",
        "  cum_rew, mean_rew = process.finalize_trajectory()\n",
        "  if episode%10 == 0:\n",
        "    print(cum_rew, mean_rew)\n",
        "  R.append(cum_rew)\n",
        "  R_.append(mean_rew)\n",
        "        \n",
        "plt.plot(R)\n",
        "plt.plot(R_)\n",
        "plt.xlabel('Episode')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Policy_Gradient_CV.py:333: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Q = torch.tensor(q,dtype = torch.float32, requires_grad=True).cuda()\n",
            "/content/Policy_Gradient_CV.py:399: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(Q[t-q,:self.action_dim+ self.state_dim].detach().clone(),dtype = torch.float32, requires_grad=True).detach().cpu()\n",
            "/content/Policy_Gradient_CV.py:400: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x,dtype = torch.float32, requires_grad=True).reshape((1,-1)).cuda()\n",
            "/content/Policy_Gradient_CV.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  p_loss = p_loss - self.values[i]*(Variable(torch.tensor(deltas[i], dtype = torch.float32)).cuda())\n",
            "/content/Policy_Gradient_CV.py:189: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  v_loss = v_loss - (log_probs[i]*(Variable(torch.tensor(deltas[i], dtype = torch.float32))).cuda()) - (0.0001*self.entropies[i].cuda()).sum()\n",
            "/content/Policy_Gradient_CV.py:196: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  utils.clip_grad_norm(self.parameters(), 40)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-45.604101555132026 -0.04564975130643847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/Policy_Gradient_CV.py:364: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(Q[t-q,:self.action_dim+ self.state_dim].detach().clone(),dtype = torch.float32, requires_grad=True).detach().cpu()\n",
            "/content/Policy_Gradient_CV.py:365: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x,dtype = torch.float32, requires_grad=True).reshape((1,-1)).cuda()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-45.3889308021498 -0.045434365167317116\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}